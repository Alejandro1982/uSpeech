<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="µSpeech : Speech recognition toolkit for the arduino" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>µSpeech</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/arjo129/uSpeech">View on GitHub</a>

          <h1 id="project_title">µSpeech</h1>
          <h2 id="project_tagline">Speech recognition toolkit for the arduino</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/arjo129/uSpeech/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/arjo129/uSpeech/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>uSpeech library</h1>

<p>The uSpeech library provides an interface for voice recognition using the Arduino. It currently produces phonemes, often the library will produce junk phonemes. Please bare with it for the time being. A noise removal function is underway.</p>

<h2>Minimum Requirements</h2>

<p>The library is quite intensive on the processor. Each sample collection takes about 3.2 milliseconds so pay close attention to the time. The library has been tested on the Arduino Uno (ATMega32). Each signal object uses up 160bytes. No real time scheduler should be used with this.</p>

<h2>Features</h2>

<ul>
<li>Letter based recognition</li>
<li>Small memory footprint</li>
<li>Arduino Compatible</li>
<li>No training required</li>
<li>Fixed point arithmetic</li>
<li>30% - 40% accuracy if based on phonemes, up to 80% if based on words.</li>
<li>Plugs directly into an <code>analogRead()</code> port</li>
</ul><h2>Documentation</h2>

<p>Commit 40 and above do not have appropriate documentation. To use µSpeech, download a copy of commit 38. 
Head over to the <a href="https://github.com/arjo129/uSpeech/downloads">downloads</a> section on github and you will find a pdf tutorial.
I'm working on closing the gap in docs please do be patient.</p>

<h2>Algorithm</h2>

<p>The library utilizes a special algorythm to enable speech detection. First the complexity of the signal is determined by taking
the absolute derivative of the signal multiplying it by a fixed point saclar and then dividing it by the absolute integral of the signal.
Consonants (other than R,L,N and M) have a value above 40 and vowels have a value below 40. To determine the vowel
a filter bank is used and the formants are extracted and matched to <a href="http://en.wikipedia.org/wiki/Formant#Formants_and_phonetics">this table</a> and determined.
As for consonants, they can be divided into frictaves and plosives. Plosives are like p or b whereas frictaves are like
s or z. Generally each band of the complexity coeficient (abs derivative over abs integral) can be matched to a small set of frictaves
and plosives. The signal determines if it is a plosive or a frictave by watching the length of the utterance (plosives occur over short periods while frictaves over long).
Finally the most appropriate character is chosen.</p>

<ul>
<li><a href="http://arjo129.github.com">Return to main page</a></li>
</ul>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">µSpeech maintained by <a href="https://github.com/arjo129">arjo129</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
