<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>µSpeech by arjo129</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>µSpeech</h1>
          <h2>Speech recognition toolkit for the arduino</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/arjo129/uSpeech/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/arjo129/uSpeech/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/arjo129/uSpeech" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h1>uSpeech library</h1>

<p>The uSpeech library provides an interface for voice recognition using the Arduino. Don't expect too much from it but you can create a very simple 10 word recognizer from this library. Feel free to fork it.</p>

<h2>Minimum Requirements</h2>

<p>The library is quite intensive on the processor. Each sample collection takes about 3.2 milliseconds so pay close attention to the time. The library has been tested on the Arduino Uno (ATMega32). Each signal object uses up 160bytes. No real time scheduler should be used with this.</p>

<h2>Features</h2>

<ul>
<li>Letter based recognition</li>
<li>Small memory footprint</li>
<li>Arduino Compatible</li>
<li>No training required</li>
<li>Fixed point arithmetic</li>
<li>30% - 40% accuracy if based on phonemes, up to 80% if based on words.</li>
<li>Plugs directly into an <code>analogRead()</code> port</li>
</ul><h2>Documentation</h2>

<p>Documentation on this library is a work in progress. There is a downloadable PDF in the <a href="https://github.com/arjo129/uSpeech/downloads">downloads</a> section with a tutorial and information about how to create your first voice-enabled project.</p>

<h2>Algorythm</h2>

<p>The library utilizes a special algorythm to enable speech detection. First the complexity of the signal is determined by taking
the absolute derivative of the signal multiplying it by a fixed point saclar and then dividing it by the absolute integral of the signal.
Consonants (other than R,L,N and M) have a value above 40 and vowels have a value below 40. To determine the vowel
a filter bank is used and the formants are extracted and matched to <a href="http://en.wikipedia.org/wiki/Formant#Formants_and_phonetics">this table</a> and determined.
As for consonants, they can be divided into frictaves and plosives. Plosives are like p or b whereas frictaves are like
s or z. Generally each band of the complexity coeficient (abs derivative over abs integral) can be matched to a small set of frictaves
and plosives. The signal determines if it is a plosive or a frictave by watching the length of the utterance (plosives occur over short periods while frictaves over long).
Finally the most appropriate character is chosen.</p>
        </section>

        <footer>
          µSpeech is maintained by <a href="https://github.com/arjo129">arjo129</a><br>
          This page was generated by <a href="http://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="http://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>